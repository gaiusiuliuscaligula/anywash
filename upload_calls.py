import requests
import json
import pandas as pd
import os
from datetime import datetime, timedelta
from google.cloud import bigquery

# –ß–∏—Ç–∞–µ–º Google Credentials –∏–∑ GitHub Secrets (–ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è)
gcp_credentials = os.getenv("GCP_SERVICE_ACCOUNT")

# –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –∫—Ä–µ–¥—ã –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª (—Ç.–∫. BigQuery —Ç—Ä–µ–±—É–µ—Ç —Ñ–∞–π–ª)
if gcp_credentials:
    creds_path = "/tmp/gcp_credentials.json"
    with open(creds_path, "w") as f:
        f.write(gcp_credentials)
    os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = creds_path
else:
    print("‚ùå –û—à–∏–±–∫–∞: GOOGLE_APPLICATION_CREDENTIALS_JSON –Ω–µ –Ω–∞–π–¥–µ–Ω!")
    exit(1)

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è API UIS
ACCESS_TOKEN = os.getenv("UIS_ACCESS_TOKEN")  # –¢–æ–∫–µ–Ω –∏–∑ GitHub Secrets
UIS_API_URL = "https://dataapi.uiscom.ru/v2.0"

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è BigQuery
BQ_PROJECT_ID = os.getenv("BQ_PROJECT_ID")  # –ü—Ä–æ–µ–∫—Ç GCP
BQ_DATASET_ID = os.getenv("BQ_DATASET_ID")  # –î–∞—Ç–∞—Å–µ—Ç –≤ BigQuery
BQ_TABLE_ID = "calls"  # –¢–∞–±–ª–∏—Ü–∞ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∑–≤–æ–Ω–∫–æ–≤

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ –∑–≤–æ–Ω–∫–æ–≤
def get_calls_report(date_from, date_till):
    headers = {"Content-Type": "application/json"}
    fields = ["id", "start_time", "finish_time", "virtual_phone_number", "finish_reason", "direction", "talk_duration"]
    calls = []
    offset = 0
    limit = 1000  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ API

    while True:
        payload = {
            "jsonrpc": "2.0",
            "id": "1",
            "method": "get.calls_report",
            "params": {
                "access_token": ACCESS_TOKEN,
                "date_from": date_from,
                "date_till": date_till,
                "offset": offset,
                "limit": limit,
                "fields": fields
            }
        }

        response = requests.post(UIS_API_URL, headers=headers, json=payload)

        if response.status_code != 200:
            print(f"‚ùå –û—à–∏–±–∫–∞ API: {response.status_code} {response.text}")
            return []

        result = response.json()
        data = result.get("result", {}).get("data", [])

        if not data:
            break  # –î–∞–Ω–Ω—ã–µ –∑–∞–∫–æ–Ω—á–∏–ª–∏—Å—å

        calls.extend(data)
        offset += limit

    return calls

# –§—É–Ω–∫—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –≤ BigQuery
def upload_to_bigquery(data):
    client = bigquery.Client(project=BQ_PROJECT_ID)
    table_ref = client.dataset(BQ_DATASET_ID).table(BQ_TABLE_ID)

    df = pd.DataFrame(data)

    if df.empty:
        print("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –≤ BigQuery.")
        return

    df["start_time"] = pd.to_datetime(df["start_time"])
    df["finish_time"] = pd.to_datetime(df["finish_time"])
    df["talk_duration"] = pd.to_numeric(df["talk_duration"], errors="coerce")

    job_config = bigquery.LoadJobConfig(write_disposition="WRITE_APPEND", autodetect=True)

    job = client.load_table_from_dataframe(df, table_ref, job_config=job_config)
    job.result()

    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π –≤ BigQuery ({BQ_TABLE_ID})")

# –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è GitHub Actions
def main():
    yesterday = datetime.utcnow() - timedelta(days=1)
    date_from = yesterday.strftime("%Y-%m-%d 00:00:00")
    date_till = yesterday.strftime("%Y-%m-%d 23:59:59")

    print(f"üîç –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –∑–≤–æ–Ω–∫–∏ —Å {date_from} –ø–æ {date_till}")
    calls = get_calls_report(date_from, date_till)

    if calls:
        upload_to_bigquery(calls)
    else:
        print("‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –∑–∞ —ç—Ç–æ—Ç –¥–µ–Ω—å.")

# –ó–∞–ø—É—Å–∫
if __name__ == "__main__":
    main()
